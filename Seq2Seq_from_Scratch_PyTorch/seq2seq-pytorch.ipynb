{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "complex-branch",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:15:54.555718Z",
     "iopub.status.busy": "2021-06-17T17:15:54.540035Z",
     "iopub.status.idle": "2021-06-17T17:16:08.481466Z",
     "shell.execute_reply": "2021-06-17T17:16:08.480742Z",
     "shell.execute_reply.started": "2021-06-17T16:45:06.122896Z"
    },
    "papermill": {
     "duration": 13.984027,
     "end_time": "2021-06-17T17:16:08.481704",
     "exception": false,
     "start_time": "2021-06-17T17:15:54.497677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (2.3.5)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (7.4.5)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.7.4)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.5)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.25.1)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.8.2)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.0)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.1.3)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.59.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.19.5)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "import torch\n",
    "import spacy\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import sys\n",
    "\n",
    "\n",
    "def translate_sentence(model, tok,  sentence, german, english, device, max_length=50):\n",
    "    # print(sentence)\n",
    "\n",
    "    # sys.exit()\n",
    "\n",
    "    # Load german tokenizer\n",
    "    spacy_ger = tok\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # print(tokens)\n",
    "\n",
    "    # sys.exit()\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, tok, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, tok, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-binary",
   "metadata": {
    "papermill": {
     "duration": 0.026755,
     "end_time": "2021-06-17T17:16:08.538532",
     "exception": false,
     "start_time": "2021-06-17T17:16:08.511777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-assurance",
   "metadata": {
    "papermill": {
     "duration": 0.026907,
     "end_time": "2021-06-17T17:16:08.593106",
     "exception": false,
     "start_time": "2021-06-17T17:16:08.566199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "owned-parallel",
   "metadata": {
    "papermill": {
     "duration": 0.026813,
     "end_time": "2021-06-17T17:16:08.646884",
     "exception": false,
     "start_time": "2021-06-17T17:16:08.620071",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sequence to Sequence Model using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-librarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:08.708368Z",
     "iopub.status.busy": "2021-06-17T17:16:08.707535Z",
     "iopub.status.idle": "2021-06-17T17:16:09.047191Z",
     "shell.execute_reply": "2021-06-17T17:16:09.046465Z",
     "shell.execute_reply.started": "2021-06-17T16:45:17.156086Z"
    },
    "papermill": {
     "duration": 0.373039,
     "end_time": "2021-06-17T17:16:09.047338",
     "exception": false,
     "start_time": "2021-06-17T17:16:08.674299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recorded-repair",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:09.115351Z",
     "iopub.status.busy": "2021-06-17T17:16:09.106959Z",
     "iopub.status.idle": "2021-06-17T17:16:26.317933Z",
     "shell.execute_reply": "2021-06-17T17:16:26.317266Z",
     "shell.execute_reply.started": "2021-06-17T16:45:17.551611Z"
    },
    "papermill": {
     "duration": 17.24324,
     "end_time": "2021-06-17T17:16:26.318110",
     "exception": false,
     "start_time": "2021-06-17T17:16:09.074870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de_core_news_sm==2.3.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 10.7 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from de_core_news_sm==2.3.0) (2.3.5)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.59.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.2)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.5)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.25.1)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.4)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.19.5)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.7.4.3)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.26.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.12.5)\r\n",
      "Building wheels for collected packages: de-core-news-sm\r\n",
      "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-py3-none-any.whl size=14907581 sha256=579eb667623d33d79cadc10aecf625d6219eef11cc7b23c3439e33fc882d8a0d\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ts1d0v4/wheels/75/30/c3/ea1c6002eede7f49c8ab017ce62a2981a87b1cd39fab6e6a65\r\n",
      "Successfully built de-core-news-sm\r\n",
      "Installing collected packages: de-core-news-sm\r\n",
      "Successfully installed de-core-news-sm-2.3.0\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('de_core_news_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "small-trace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:26.413715Z",
     "iopub.status.busy": "2021-06-17T17:16:26.412467Z",
     "iopub.status.idle": "2021-06-17T17:16:41.323990Z",
     "shell.execute_reply": "2021-06-17T17:16:41.322409Z",
     "shell.execute_reply.started": "2021-06-17T16:45:30.914117Z"
    },
    "papermill": {
     "duration": 14.964773,
     "end_time": "2021-06-17T17:16:41.324147",
     "exception": false,
     "start_time": "2021-06-17T17:16:26.359374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 4.9 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.59.0)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.1)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.0.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.12.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exposed-charlotte",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:41.448356Z",
     "iopub.status.busy": "2021-06-17T17:16:41.447323Z",
     "iopub.status.idle": "2021-06-17T17:16:41.460080Z",
     "shell.execute_reply": "2021-06-17T17:16:41.459499Z",
     "shell.execute_reply.started": "2021-06-17T16:45:41.283276Z"
    },
    "papermill": {
     "duration": 0.076669,
     "end_time": "2021-06-17T17:16:41.460228",
     "exception": false,
     "start_time": "2021-06-17T17:16:41.383559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import de_core_news_sm\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ruled-brick",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:41.583674Z",
     "iopub.status.busy": "2021-06-17T17:16:41.582786Z",
     "iopub.status.idle": "2021-06-17T17:16:44.512136Z",
     "shell.execute_reply": "2021-06-17T17:16:44.512950Z",
     "shell.execute_reply.started": "2021-06-17T16:45:41.297503Z"
    },
    "papermill": {
     "duration": 2.995017,
     "end_time": "2021-06-17T17:16:44.513211",
     "exception": false,
     "start_time": "2021-06-17T17:16:41.518194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spacy_ger = de_core_news_sm.load()\n",
    "spacy_eng = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frozen-shore",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:44.737249Z",
     "iopub.status.busy": "2021-06-17T17:16:44.736021Z",
     "iopub.status.idle": "2021-06-17T17:16:44.740829Z",
     "shell.execute_reply": "2021-06-17T17:16:44.741637Z",
     "shell.execute_reply.started": "2021-06-17T16:45:43.765251Z"
    },
    "papermill": {
     "duration": 0.119396,
     "end_time": "2021-06-17T17:16:44.741922",
     "exception": false,
     "start_time": "2021-06-17T17:16:44.622526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenizer_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def tokenizer_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confidential-combining",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:44.944130Z",
     "iopub.status.busy": "2021-06-17T17:16:44.940810Z",
     "iopub.status.idle": "2021-06-17T17:16:44.948626Z",
     "shell.execute_reply": "2021-06-17T17:16:44.947639Z",
     "shell.execute_reply.started": "2021-06-17T16:45:43.774296Z"
    },
    "papermill": {
     "duration": 0.110879,
     "end_time": "2021-06-17T17:16:44.948829",
     "exception": false,
     "start_time": "2021-06-17T17:16:44.837950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "german = Field(tokenize=tokenizer_ger, lower=True,\n",
    "              init_token='<sos>', eos_token='<eos>')\n",
    "english = Field(tokenize=tokenizer_eng, lower=True,\n",
    "               init_token='<sos>', eos_token='<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unexpected-groove",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:45.152567Z",
     "iopub.status.busy": "2021-06-17T17:16:45.151527Z",
     "iopub.status.idle": "2021-06-17T17:16:53.852942Z",
     "shell.execute_reply": "2021-06-17T17:16:53.851817Z",
     "shell.execute_reply.started": "2021-06-17T16:45:43.788077Z"
    },
    "papermill": {
     "duration": 8.808068,
     "end_time": "2021-06-17T17:16:53.853094",
     "exception": false,
     "start_time": "2021-06-17T17:16:45.045026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 10.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.73MB/s]\n",
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data, test_data = Multi30k.splits(exts=('.de','.en'),\n",
    "                                                        fields=(german, english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "satisfied-consequence",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:54.003324Z",
     "iopub.status.busy": "2021-06-17T17:16:53.987671Z",
     "iopub.status.idle": "2021-06-17T17:16:54.318480Z",
     "shell.execute_reply": "2021-06-17T17:16:54.317799Z",
     "shell.execute_reply.started": "2021-06-17T16:45:53.965474Z"
    },
    "papermill": {
     "duration": 0.404069,
     "end_time": "2021-06-17T17:16:54.318645",
     "exception": false,
     "start_time": "2021-06-17T17:16:53.914576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-cruise",
   "metadata": {
    "papermill": {
     "duration": 0.060039,
     "end_time": "2021-06-17T17:16:54.440222",
     "exception": false,
     "start_time": "2021-06-17T17:16:54.380183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-penguin",
   "metadata": {
    "papermill": {
     "duration": 0.058931,
     "end_time": "2021-06-17T17:16:54.562538",
     "exception": false,
     "start_time": "2021-06-17T17:16:54.503607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confidential-clerk",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:54.693887Z",
     "iopub.status.busy": "2021-06-17T17:16:54.692876Z",
     "iopub.status.idle": "2021-06-17T17:16:54.696477Z",
     "shell.execute_reply": "2021-06-17T17:16:54.695932Z",
     "shell.execute_reply.started": "2021-06-17T16:45:54.253319Z"
    },
    "papermill": {
     "duration": 0.07285,
     "end_time": "2021-06-17T17:16:54.696624",
     "exception": false,
     "start_time": "2021-06-17T17:16:54.623774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, d_ratio):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.dropout = nn.Dropout(d_ratio)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=d_ratio)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (seq_length, batch_size)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x)) # shape: (seq_length, batch_size, embedding_size)\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-findings",
   "metadata": {
    "papermill": {
     "duration": 0.06304,
     "end_time": "2021-06-17T17:16:54.820379",
     "exception": false,
     "start_time": "2021-06-17T17:16:54.757339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inside-arrest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:54.952629Z",
     "iopub.status.busy": "2021-06-17T17:16:54.951461Z",
     "iopub.status.idle": "2021-06-17T17:16:54.954269Z",
     "shell.execute_reply": "2021-06-17T17:16:54.954992Z",
     "shell.execute_reply.started": "2021-06-17T16:47:24.538909Z"
    },
    "papermill": {
     "duration": 0.0726,
     "end_time": "2021-06-17T17:16:54.955179",
     "exception": false,
     "start_time": "2021-06-17T17:16:54.882579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size,\n",
    "                output_size, num_layers, d_ratio):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layer = num_layers\n",
    "        \n",
    "        self.dropout = nn.Dropout(d_ratio)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = d_ratio)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        \n",
    "        x = x.unsqueeze(0) # x shape: (N) => (1,N)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x)) # shape: (1,batch_size, embedding_size)\n",
    "        outputs, (hidden, cell) = self.rnn(embedding, (hidden,cell)) # outputs shape: (1, batch_size, hidden_size)\n",
    "        predictions = self.fc(outputs) # predictions shape: (1, batch_size, vocab_length)\n",
    "        \n",
    "        predictions = predictions.squeeze(0)\n",
    "        \n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "saved-figure",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:55.084698Z",
     "iopub.status.busy": "2021-06-17T17:16:55.083583Z",
     "iopub.status.idle": "2021-06-17T17:16:55.086861Z",
     "shell.execute_reply": "2021-06-17T17:16:55.086355Z",
     "shell.execute_reply.started": "2021-06-17T16:47:24.670037Z"
    },
    "papermill": {
     "duration": 0.071772,
     "end_time": "2021-06-17T17:16:55.086996",
     "exception": false,
     "start_time": "2021-06-17T17:16:55.015224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self, source, target, teacher_force_ratio = 0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)\n",
    "                \n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "        \n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # start token\n",
    "        x = target[0]\n",
    "        \n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            best_guess = output.argmax(1)\n",
    "            \n",
    "            x = target[t] if random.random() < teacher_force_ratio else best_guess\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-today",
   "metadata": {
    "papermill": {
     "duration": 0.061103,
     "end_time": "2021-06-17T17:16:55.209150",
     "exception": false,
     "start_time": "2021-06-17T17:16:55.148047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "absent-isaac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:55.392907Z",
     "iopub.status.busy": "2021-06-17T17:16:55.391869Z",
     "iopub.status.idle": "2021-06-17T17:16:55.395553Z",
     "shell.execute_reply": "2021-06-17T17:16:55.395010Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.037815Z"
    },
    "papermill": {
     "duration": 0.125806,
     "end_time": "2021-06-17T17:16:55.395712",
     "exception": false,
     "start_time": "2021-06-17T17:16:55.269906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "# Model Hyperparameters\n",
    "load_model = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size_encoder = len(german.vocab)\n",
    "input_size_decoder = len(english.vocab)\n",
    "output_size = len(english.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caroline-electronics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:16:55.521686Z",
     "iopub.status.busy": "2021-06-17T17:16:55.520732Z",
     "iopub.status.idle": "2021-06-17T17:17:01.378982Z",
     "shell.execute_reply": "2021-06-17T17:17:01.378350Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.107815Z"
    },
    "papermill": {
     "duration": 5.922477,
     "end_time": "2021-06-17T17:17:01.379149",
     "exception": false,
     "start_time": "2021-06-17T17:16:55.456672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensot board\n",
    "writer = SummaryWriter(f'runs/loss_plot')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cutting-contribution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:17:01.550292Z",
     "iopub.status.busy": "2021-06-17T17:17:01.549282Z",
     "iopub.status.idle": "2021-06-17T17:17:01.559336Z",
     "shell.execute_reply": "2021-06-17T17:17:01.558750Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.277524Z"
    },
    "papermill": {
     "duration": 0.119698,
     "end_time": "2021-06-17T17:17:01.559483",
     "exception": false,
     "start_time": "2021-06-17T17:17:01.439785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, validation_data, test_data),\n",
    "    batch_size = batch_size,\n",
    "    sort_within_batch = True,\n",
    "    sort_key = lambda x: len(x.src),\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "educational-hypothetical",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:17:01.789812Z",
     "iopub.status.busy": "2021-06-17T17:17:01.788986Z",
     "iopub.status.idle": "2021-06-17T17:17:10.260114Z",
     "shell.execute_reply": "2021-06-17T17:17:10.259349Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.348947Z"
    },
    "papermill": {
     "duration": 8.586824,
     "end_time": "2021-06-17T17:17:10.260309",
     "exception": false,
     "start_time": "2021-06-17T17:17:01.673485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_net = Encoder(input_size_encoder, encoder_embedding_size,\n",
    "                      hidden_size, num_layers, enc_dropout).to(device)\n",
    "decoder_net = Decoder(input_size_decoder, decoder_embedding_size, \n",
    "                      hidden_size, output_size, num_layers, dec_dropout).to(device)\n",
    "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "helpful-precipitation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:17:10.393796Z",
     "iopub.status.busy": "2021-06-17T17:17:10.392696Z",
     "iopub.status.idle": "2021-06-17T17:17:10.396413Z",
     "shell.execute_reply": "2021-06-17T17:17:10.395804Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.688206Z"
    },
    "papermill": {
     "duration": 0.071954,
     "end_time": "2021-06-17T17:17:10.396559",
     "exception": false,
     "start_time": "2021-06-17T17:17:10.324605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pad_idx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wanted-norwegian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:17:10.526549Z",
     "iopub.status.busy": "2021-06-17T17:17:10.525452Z",
     "iopub.status.idle": "2021-06-17T17:17:10.529332Z",
     "shell.execute_reply": "2021-06-17T17:17:10.528789Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.696621Z"
    },
    "papermill": {
     "duration": 0.070689,
     "end_time": "2021-06-17T17:17:10.529495",
     "exception": false,
     "start_time": "2021-06-17T17:17:10.458806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spanish-stanley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:17:10.660659Z",
     "iopub.status.busy": "2021-06-17T17:17:10.659569Z",
     "iopub.status.idle": "2021-06-17T17:17:10.663211Z",
     "shell.execute_reply": "2021-06-17T17:17:10.662626Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.736979Z"
    },
    "papermill": {
     "duration": 0.071429,
     "end_time": "2021-06-17T17:17:10.663451",
     "exception": false,
     "start_time": "2021-06-17T17:17:10.592022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "radical-surveillance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T17:17:10.797354Z",
     "iopub.status.busy": "2021-06-17T17:17:10.796595Z",
     "iopub.status.idle": "2021-06-17T17:32:00.595038Z",
     "shell.execute_reply": "2021-06-17T17:32:00.596994Z",
     "shell.execute_reply.started": "2021-06-17T16:47:25.962906Z"
    },
    "papermill": {
     "duration": 889.873095,
     "end_time": "2021-06-17T17:32:00.597797",
     "exception": false,
     "start_time": "2021-06-17T17:17:10.724702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['b', 'age', 'members', 'members', 'walked', 'walked', 'measuring', 'medieval', 'medieval', 'measuring', 'conductor', 'son', 'mouse', 'mouse', 'clothed', 'clothed', 'clothed', 'clothed', 'clothed', 'clothed', 'clothed', 'clothed', 'atlanta', 'atlanta', 'atlanta', 'purse', 'formation', 'paddling', 'bemused', 'cable', 'cable', 'trucks', 'trucks', 'pulls', 'pulls', 'pulls', 'dutch', 'dutch', 'heads', 'drawing', 'hokey', 'hokey', 'numerous', 'bib', 'restaurant', 'spike', 'laboratory', 'rainy', 'joy', 'joy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'black', 'and', 'a', 'black', 'and', 'a', 'black', 'and', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 2 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'baseball', 'player', 'with', 'a', '<unk>', 'is', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 3 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', '<unk>', 'with', 'with', 'a', '<unk>', '<unk>', '<unk>', 'to', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 4 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'street', 'with', 'with', 'a', '<unk>', 'to', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 5 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'street', 'with', 'with', 'a', '<unk>', 'with', 'a', '<unk>', '<unk>', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 6 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'street', 'with', 'with', 'a', 'large', 'of', 'a', 'is', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 7 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'taxi', 'with', 'with', 'a', 'number', 'pulled', 'is', 'being', 'pulled', 'by', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 8 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'street', 'with', 'with', 'a', 'being', 'pulled', 'by', 'a', 'large', 'from', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 9 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'building', 'with', 'many', 'passengers', 'pulled', 'by', 'a', 'large', 'of', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 10 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'many', 'people', 'from', 'a', 'large', 'from', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 11 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'building', 'with', 'many', 'men', 'being', 'pulled', 'by', 'a', 'large', 'surrounded', 'by', 'a', '.', '<eos>']\n",
      "[Epoch 12 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'passengers', 'pulled', 'by', 'a', 'large', 'of', 'a', 'large', '.', '<eos>']\n",
      "[Epoch 13 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'men', 'is', 'pulled', 'by', 'a', 'large', 'large', 'of', 'a', '.', '<eos>']\n",
      "[Epoch 14 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'men', 'pulled', 'by', 'a', 'from', 'a', 'large', 'cable', '.', '<eos>']\n",
      "[Epoch 15 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'men', 'pulled', 'pulled', 'by', 'a', 'boat', 'from', 'a', 'large', 'boat', '.', '<eos>']\n",
      "[Epoch 16 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'men', 'pulled', 'by', 'a', 'large', 'boat', 'from', 'the', 'end', 'of', 'a', '<unk>', '.', '<eos>']\n",
      "[Epoch 17 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'men', 'pulled', 'pulled', 'by', 'a', 'large', 'by', 'a', 'large', '.', '<eos>']\n",
      "[Epoch 18 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'men', 'pulled', 'pulled', 'pulled', 'from', 'a', 'boat', 'from', 'a', 'boat', '.', '<eos>']\n",
      "[Epoch 19 / 20]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['a', 'boat', 'with', 'many', 'men', 'pulled', 'pulled', 'pulled', 'by', 'a', 'large', 'by', 'a', 'large', 'horses', '.', '<eos>']\n",
      "Bleu score 18.47\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    checkpoint = {\"state_dict\": model.state_dict(), \"optimizer\": optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, spacy_ger, sentence, german, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target)\n",
    "\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "\n",
    "score = bleu(test_data[1:100], spacy_ger, model, german, english, device)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-disney",
   "metadata": {
    "papermill": {
     "duration": 0.14002,
     "end_time": "2021-06-17T17:32:00.880287",
     "exception": false,
     "start_time": "2021-06-17T17:32:00.740267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-morris",
   "metadata": {
    "papermill": {
     "duration": 0.138964,
     "end_time": "2021-06-17T17:32:01.155504",
     "exception": false,
     "start_time": "2021-06-17T17:32:01.016540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-walter",
   "metadata": {
    "papermill": {
     "duration": 0.123601,
     "end_time": "2021-06-17T17:32:01.405785",
     "exception": false,
     "start_time": "2021-06-17T17:32:01.282184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-palestinian",
   "metadata": {
    "papermill": {
     "duration": 0.122556,
     "end_time": "2021-06-17T17:32:01.655850",
     "exception": false,
     "start_time": "2021-06-17T17:32:01.533294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 978.277767,
   "end_time": "2021-06-17T17:32:04.466537",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-17T17:15:46.188770",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
